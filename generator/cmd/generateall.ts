import * as constants from '../constants';
import { cloneAndGenerateBasePaths, validateAndReturnReadmePath } from '../specs';
import { SchemaConfiguration, generateSchemas, clearAutogeneratedSchemaRefs, saveAutogeneratedSchemaRefs } from '../generate';
import { getWhitelist } from '../whitelist';
import chalk from 'chalk';
import { flatten, chunk } from 'lodash';
import { executeSynchronous, chunker } from '../utils';

interface GenerateAllParams {
    batchCount?: number,
    batchIndex?: number,
}

function parseParams(): GenerateAllParams {
    if (!process.argv[2]) {
        return {};
    }

    return JSON.parse(process.argv[2]);
}

executeSynchronous(async () => {
    const params = parseParams();

    let filteredWhitelist = getWhitelist();
    if (params.batchCount !== undefined && params.batchIndex !== undefined) {
        filteredWhitelist = chunker(filteredWhitelist, params.batchCount)[params.batchIndex];
    }

    await cloneAndGenerateBasePaths(constants.specsRepoPath, constants.specsRepoUri, constants.specsRepoCommitHash);

    await clearAutogeneratedSchemaRefs(filteredWhitelist);

    const schemaConfigs: SchemaConfiguration[] = [];
    const errors = [];
    for (const whitelistConfig of filteredWhitelist) {
        try {
            const readme = await validateAndReturnReadmePath(whitelistConfig.basePath);

            const newConfigs = await generateSchemas(readme, whitelistConfig);
            schemaConfigs.push(...newConfigs);
        } catch(error) {
            console.log(chalk.red(`Caught exception processing whitelist entry ${whitelistConfig.basePath}.`));
            console.log(chalk.red(error));
    
            errors.push(error);
        }
    }

    await saveAutogeneratedSchemaRefs(flatten(schemaConfigs));

    if (errors.length > 0) {
        throw new Error(`Autogeneration failed with ${errors.length} errors. See logs for detailed information.`);
    }
});